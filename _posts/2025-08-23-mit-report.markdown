---
layout: post
title:  "MIT Reports that 95% of enterprise AI fails! What does it really mean?"
categories: posts
image: /assets/img/posts/mit_gen_ai.png
image1: /assets/img/posts/mit_gen_ai.png
#image2: /assets/img/posts/venturebeat.webp
---

MIT just dropped a *[report](https://mlq.ai/media/quarterly_decks/v0.1_State_of_AI_in_Business_2025_Report.pdf)* indicating that despite $30–40 billion in enterprise investment into GenAI, only **5% succeed** in generating substantial returns, while **95% of the investment is essentially going to waste**.

The report naturally made it to the headlines. While its conclusion is dramatic in its implications, MIT provides a breakdown of why 95% fail while 5% succeed. Without looking closely, it’s easy to deduce that AI is failing to deliver. However, after reading the report, I find that it paints a very different picture. Here is an executive summary of its key points and takeaways.

<figure>
  <img src="{{ page.image1 }}">
</figure>

---

### What is the report all about?

1. It divides organizations into two categories (or sides) — **"The GenAI Divide"**:
   - **The wrong side**: 95% of organizations that fail in building, buying, adopting, or integrating AI to create value, ultimately burning money and time without results.
   - **The right side**: The 5% of organizations that succeed in creating or buying AI tools that produce measurable value and generate substantial return on investment.

2. It provides a breakdown of:
   - Reasons why organizations end up on the *right* or *wrong* side.
   - Adoption and integration of AI - from the individual level to the enterprise level.
   - Best practices for crossing from the *wrong* side to the *right* side of the "divide".

3. It is important to note that the insights gathered in this report are based on interviews, surveys, and public sources, rather than statistical data reported by organizations themselves, and therefore should be taken with a grain of salt.

---

### So why do 95% fail?

The report identifies three main reasons:

1. **Building custom "generic" AI tools** that fail due to brittleness, inability to adapt or learn from feedback, and misaligned outputs (that do not match the needs, or expectations of the organization). These often perform worse than widely used tools such as GPT or Claude, which are more flexible, produce better results, and are faster to integrate since they require no IT setup.
2. **Investment bias**: Most GenAI investment is funneled into sales and marketing (~50–70%). In contrast, back-office functions (procurement, finance, compliance) often deliver higher ROI through efficiency gains, but remain underfunded since their impact is harder to quantify.
3. **Shadow AI**: Employees use personal AI tools to increase their productivity, often daily, but companies fail to capture or scale this usage into official enterprise systems and translate it into business-level value.

---

### Why do 5% succeed?

1. They build **tailored tools** that are deeply customized to a specific workflow or business use case. These tools can *retain memory*, learn from *business data*, and adapt from *feedback*. Let's break these down:
   - **Retain memory**: Unlike ChatGPT, which forgets context between sessions (requiring users to re-enter instructions and preferences each time), a memory-capable system stores organizational knowledge such as client preferences, document history, or workflow rules, and recalls it automatically.
   - **Learn from business data**: While we cannot “teach” ChatGPT to learn from company-specific data, customized tools can be trained and fine-tuned to do so.
   - **Learn from feedback**: Unlike most tools today that repeat the same mistakes even after corrections, a learning-capable system adapts based on user feedback, improving performance over time.

2. Successful organizations **start small**, in specific workflows where ROI is clear, and only then expand into broader use cases.
3. Analyze which personal tools (ChatGPT, Claude, etc.) employees use and find valuable, then use these insights to guide adoption decisions and turn ad-hoc, unsanctioned productivity hacks into secure, integrated systems that scale across the business.


### The role of Agentic AI

The report highlights Agentic AI as the emerging solution: systems designed with persistent memory, iterative learning, and autonomous workflow orchestration. These capabilities directly address the integration and learning challenges that block most GenAI tools today (as mentioned above).

---

### Conclusion

I believe this is an important report that aligns with the views of leading AI experts and educators (such as Andrew Ng, Yann Lecun, and Gary Marcus, to name just a few), as well as with what I wrote a year ago in [this post](https://aloneirew.github.io/posts/2024/05/01/from-proof-of-concept.html). In most cases, building smaller, tailored models makes more sense than attempting to build a generic model that is a jack of all trades, especially in terms of cost, time, and risk.
For me, the biggest takeaway is that success in AI is not about the technology itself, but about how thoughtfully it is applied.
